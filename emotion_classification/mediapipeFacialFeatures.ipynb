{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from IPython.display import display, Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T13:33:55.264333Z",
     "start_time": "2023-11-07T13:33:49.343315900Z"
    }
   },
   "id": "affcd425dfc84424"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-07T13:33:55.278331400Z",
     "start_time": "2023-11-07T13:33:55.264333Z"
    }
   },
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "def extract_face_landmarks(image_path):\n",
    "    # image = cv2.imread(image_path)\n",
    "    image = image_path\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "        results = face_mesh.process(image_rgb)\n",
    "        if results.multi_face_landmarks:\n",
    "          landmarks = results.multi_face_landmarks[0].landmark\n",
    "        else:\n",
    "          return None\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mediapipe.python.solutions.face_mesh' has no attribute 'process'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m image_rgb \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mcvtColor(image, cv2\u001B[38;5;241m.\u001B[39mCOLOR_BGR2RGB)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Perform face detection\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mmp_face_mesh\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess\u001B[49m(image_rgb)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m results\u001B[38;5;241m.\u001B[39mdetections:\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m detection \u001B[38;5;129;01min\u001B[39;00m results\u001B[38;5;241m.\u001B[39mdetections:\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'mediapipe.python.solutions.face_mesh' has no attribute 'process'"
     ]
    }
   ],
   "source": [
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)  # 0 indicates the default camera (you can change this number if you have multiple cameras)\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the camera\n",
    "    ret, image = cap.read()\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform face detection\n",
    "    results = face_detection.process(image_rgb)\n",
    "\n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            mp_drawing.draw_detection(image, detection)\n",
    "\n",
    "    # Show the resulting image\n",
    "    cv2.imshow('Facial Features Detection', image)\n",
    "\n",
    "    # Exit loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T13:36:26.535927200Z",
     "start_time": "2023-11-07T13:36:25.130082700Z"
    }
   },
   "id": "35e2bfbe052f0f0a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize Mediapipe Face Mesh components\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize OpenCV video capture\n",
    "cap = cv2.VideoCapture(0)  # You can change the argument to a file path if you want to process a video file\n",
    "\n",
    "# Initialize the Face Mesh module\n",
    "with mp_face_mesh.FaceMesh(\n",
    "        min_detection_confidence=0.1,\n",
    "        min_tracking_confidence=0.1) as face_mesh:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the camera\n",
    "        ret, image = cap.read()\n",
    "\n",
    "        # Convert the image to RGB\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Perform face mesh detection\n",
    "        results = face_mesh.process(image_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                for idx, landmark in enumerate(face_landmarks.landmark):\n",
    "                    if idx in [0, 11, 12, 13, 14, 15, 16, 17]:\n",
    "                        h, w, c = image.shape\n",
    "                        cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "                        cv2.circle(image, (cx, cy), 2, (0, 255, 0), -1)\n",
    "\n",
    "        # Show the resulting image\n",
    "        cv2.imshow('Face Mesh', image)\n",
    "\n",
    "        # Exit loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T13:47:36.307855700Z",
     "start_time": "2023-11-07T13:47:29.296043200Z"
    }
   },
   "id": "fc21057b1eeda82f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2d990f7d72bd13cc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
